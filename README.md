# Reto DBA OlaClick

**Autor:** Kevin Valverde Bejarano  
**Fecha:** 20/07/2025

---

## üîç Parte 1: Modelado de Datos (Relacional)

### Requerimiento:

Dise√±a un modelo de datos relacional en PostgreSQL para soportar:

- Restaurantes con m√∫ltiples sucursales
- Clientes que realizan pedidos
- Pedidos que contienen uno o m√°s productos
- Estado de cada pedido (`initiated`, `sent`, `delivered`)
- Registro de cambios de estado (con timestamp)

## Entregables

### **Entregable 1**  

**üé• [Clic aqu√≠ para ver el video de Craci√≥n de BD](https://doem2yl3c8x6l.cloudfront.net/reto/Reto-Olaclick.mp4)**

***A continuaci√≥n, se comparte el Script SQL para la Creaci√≥n de Tablas e √çndices***

```sql
-- ENUMs (tipo de datos)
CREATE TYPE order_status AS ENUM ('initiated', 'sent', 'delivered');
CREATE TYPE user_status AS ENUM ('A', 'I', 'B'); -- A: Activo, I: Inactivo, B: Bloqueado

-- Tabla: restaurants
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabla: users
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
    username VARCHAR(100) NOT NULL UNIQUE,
    full_name VARCHAR(150),
    role VARCHAR(50),
    email VARCHAR(100) UNIQUE,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status user_status NOT NULL
);

-- Agregar FK circular tras creaci√≥n de users
ALTER TABLE restaurants
ADD COLUMN created_by_user_id INTEGER REFERENCES users(id);

-- Tabla: branches
CREATE TABLE branches (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    address TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by_user_id INTEGER REFERENCES users(id)
);

-- Tabla: clients
CREATE TABLE clients (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) NOT NULL,
    phone VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE (restaurant_id, email),
    created_by_user_id INTEGER REFERENCES users(id)
);

-- Tabla: products
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    price NUMERIC(10,2) NOT NULL CHECK (price >= 0),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by_user_id INTEGER REFERENCES users(id)
);

-- Tabla: orders
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
    client_id INTEGER NOT NULL REFERENCES clients(id),
    branch_id INTEGER NOT NULL REFERENCES branches(id),
    total NUMERIC(10,2) NOT NULL DEFAULT 0,
    status order_status NOT NULL DEFAULT 'initiated',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by_user_id INTEGER REFERENCES users(id)
);

-- Tabla: order_details
CREATE TABLE order_details (
    order_id INTEGER NOT NULL REFERENCES orders(id) ON DELETE CASCADE,
    product_id INTEGER NOT NULL REFERENCES products(id),
    quantity INTEGER NOT NULL CHECK (quantity > 0),
    price NUMERIC(10,2) NOT NULL CHECK (price >= 0),
    created_by_user_id INTEGER REFERENCES users(id),
    PRIMARY KEY (order_id, product_id)
);

-- Tabla: order_status_history
CREATE TABLE order_status_history (
    id SERIAL PRIMARY KEY,
    order_id INTEGER NOT NULL REFERENCES orders(id) ON DELETE CASCADE,
    status order_status NOT NULL,
    changed_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    created_by_user_id INTEGER REFERENCES users(id)
);

-- √çndices
-- √çndices en tabla users
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_restaurant ON users(restaurant_id, status);

--√çndices en tabla clients
CREATE INDEX idx_clients_name ON clients(restaurant_id, name);
CREATE INDEX idx_clients_phone ON clients(restaurant_id, phone);
CREATE INDEX idx_clients_restaurant_email ON clients(restaurant_id, email);

-- √çndices en tabla products
CREATE INDEX idx_products_name ON products(restaurant_id, name);

-- √çndices en tabla branches
CREATE INDEX idx_branches_name ON branches(restaurant_id, name);

-- √çndices en tabla orders
CREATE INDEX idx_orders_restaurant_status_created ON orders(restaurant_id, status, created_at);
CREATE INDEX idx_orders_created_at ON orders(restaurant_id, created_at);
CREATE INDEX idx_orders_client_date ON orders(client_id, created_at);
CREATE INDEX idx_orders_restaurant_client ON orders(restaurant_id, client_id);
CREATE INDEX idx_orders_restaurant_branch ON orders(restaurant_id, branch_id);
CREATE INDEX idx_orders_branch ON orders(branch_id);

-- √çndices en order_status_history
CREATE INDEX idx_order_status_history_order ON order_status_history(order_id);
CREATE INDEX idx_order_status_changed_at ON order_status_history(changed_at);

-- √çndices en order_details
CREATE INDEX idx_order_details_product ON order_details(product_id);
```
***Adicional comparto el Script para insertar informaci√≥n en las tablas***

```sql
-- Insertar 50 restaurantes
INSERT INTO restaurants (name, created_at)
SELECT 'Restaurant ' || i,
       NOW() - (random() * interval '30 days')
FROM generate_series(1,50) i;

-- Insertar 50 usuarios por restaurante
INSERT INTO users (restaurant_id, username, full_name, role, email, password_hash, status, created_at)
SELECT r.id,
       'user_' || r.id || '_' || i,
       'User ' || i || ' R' || r.id,
       CASE WHEN i % 10 = 0 THEN 'admin' ELSE 'staff' END,
       'user' || i || '_r' || r.id || '@mail.com',
       md5(random()::text),
       (
         CASE 
           WHEN random() < 0.8 THEN 'A'
           WHEN random() < 0.9 THEN 'I'
           ELSE 'B'
         END
       )::user_status,
       NOW() - (random() * interval '30 days')
FROM restaurants r,
     generate_series(1,50) i;

-- Insertar 10 sucursales por restaurante
INSERT INTO branches (restaurant_id, name, address, created_at)
SELECT r.id,
       'Sucursal ' || i || ' R' || r.id,
       'Avenida Principal #' || (100 + i),
       NOW() - (random() * interval '30 days')
FROM restaurants r,
     generate_series(1,10) i;

-- Insertar 200 clientes por restaurante
INSERT INTO clients (restaurant_id, name, email, phone, created_at)
SELECT r.id,
       'Cliente ' || i || ' R' || r.id,
       'cliente' || i || '_r' || r.id || '@mail.com',
       '9' || trunc(random() * 100000000)::text,
       NOW() - (random() * interval '30 days')
FROM restaurants r,
     generate_series(1,200) i;

-- Insertar 100 productos por restaurante
INSERT INTO products (restaurant_id, name, description, price, created_at)
SELECT r.id,
       'Producto ' || i || ' R' || r.id,
       'Descripci√≥n del producto ' || i,
       ROUND((random()*90 + 10)::numeric, 2),   -- ‚úÖ CAST A NUMERIC ANTES DE ROUND
       NOW() - (random() * interval '30 days')
FROM restaurants r,
     generate_series(1,100) i;

-- Insertar 10‚ÄØ000 pedidos con fecha aleatoria
WITH all_clients AS (
    SELECT c.id AS client_id, 
           c.restaurant_id, 
           (SELECT b.id FROM branches b WHERE b.restaurant_id = c.restaurant_id ORDER BY random() LIMIT 1) AS branch_id
    FROM clients c
)
INSERT INTO orders (restaurant_id, client_id, branch_id, total, status, created_at)
SELECT ac.restaurant_id,
       ac.client_id,
       ac.branch_id,
       0, -- se actualiza luego
       'initiated',
       -- 40% de pedidos estar√°n en los √∫ltimos 7 d√≠as, el resto en √∫ltimos 30
       CASE WHEN random() < 0.4 
            THEN NOW() - (random() * interval '7 days')
            ELSE NOW() - (random() * interval '30 days')
       END
FROM all_clients ac
ORDER BY random()
LIMIT 10000;

-- Insertar detalles a cada pedido (1 a 5 productos aleatorios)
DO $$
DECLARE
    o RECORD;
    prod RECORD;
    num_items INT;
    total_order NUMERIC(10,2);
BEGIN
    FOR o IN SELECT id, restaurant_id FROM orders LOOP
        total_order := 0;
        num_items := 1 + floor(random() * 5);
        FOR prod IN
            SELECT id, price FROM products p
            WHERE p.restaurant_id = o.restaurant_id
            ORDER BY random()
            LIMIT num_items
        LOOP
            INSERT INTO order_details (order_id, product_id, quantity, price, created_by_user_id)
            VALUES (
                o.id, 
                prod.id, 
                (1 + floor(random() * 3))::int, 
                prod.price,
                NULL
            );
            total_order := total_order + prod.price;
        END LOOP;
        UPDATE orders SET total = total_order WHERE id = o.id;
    END LOOP;
END $$;

-- Crear historial de estados para cada pedido con l√≥gica temporal
DO $$
DECLARE
    o RECORD;
BEGIN
    FOR o IN SELECT id, created_at FROM orders LOOP
        -- siempre tiene initiated
        INSERT INTO order_status_history (order_id, status, changed_at)
        VALUES (o.id, 'initiated', o.created_at);

        -- 60% avanzan a sent en promedio 1-3 d√≠as despu√©s
        IF random() < 0.6 THEN
            INSERT INTO order_status_history (order_id, status, changed_at)
            VALUES (
                o.id, 
                'sent',
                o.created_at + (random() * interval '3 days')
            );
            UPDATE orders 
              SET status = 'sent' 
              WHERE id = o.id;

            -- 30% de esos se entregan despu√©s de 1-5 d√≠as
            IF random() < 0.5 THEN
                INSERT INTO order_status_history (order_id, status, changed_at)
                VALUES (
                    o.id, 
                    'delivered',
                    o.created_at + (3 + random() * 5) * interval '1 day'
                );
                UPDATE orders 
                  SET status = 'delivered' 
                  WHERE id = o.id;
            END IF;
        END IF;
    END LOOP;
END $$;
```

### **Entregable 2**

***justificaci√≥n de modelado***

El modelado realizado se justifica en los siguientes 9 enunciados:

1. Se aplic√≥ un dise√±o normalizado 3NF lo cual nos permite:
   - Eliminar redudancia
   - Facilita la mantenibilidad
   - Reduce errores de inconsistencia

2. Multitenant para soporte a multiples restaurantes  

   Todas las entidades contienen el campo *restaurant_id* para:
   - Garantizar que los datos est√©n aislados por restaurante, fundamental en una arquitectura SaaS multicliente.
   - Permitir segmentaci√≥n l√≥gica sin necesidad de m√∫ltiples bases de datos.  

   Se dise√±aron √≠ndices compuestos con *restaurant_id* para que las consultas filtradas por empresa sean eficientes.

3. Trazabilidad de usuarios  

   Cada tabla relevante incluye el campo *created_by_user_id*, que nos permite saber:
   - Qui√©n cre√≥ cada registro, para auditor√≠a y an√°lisis.
   - Este campo se relaciona con la tabla *users*.  

   Esto fortalece el control y la rendici√≥n de cuentas en entornos regulados o multiusuario.

4. Tipo de datos adecuados  

   Eleg√≠ los tipos seg√∫n el uso y buenas pr√°cticas de PostgreSQL (VARCHAR(n), TEXT, NUMERIC(10,2), TIMESTAMP, ENUM).

5. Constraints y Reglas de Integridad
   
   - Se aplicaron llaves for√°neas (FOREIGN KEY) para mantener relaciones v√°lidas entre tablas.
   - Uso de ON DELETE CASCADE en entidades hijas, para evitar registros hu√©rfanos.
   - Restricciones de unicidad como (restaurant_id, email) aseguran que un cliente no se repita dentro del mismo restaurante.

6. √çndices dise√±ados para rendimiento  

   Se crearon √≠ndices estrat√©gicos considerando los principales patrones de consulta:
   - orders(restaurant_id, status, created_at): para buscar pedidos recientes por estado.
   - clients(restaurant_id, email): para b√∫squedas de clientes por correo en una empresa.
   - products(restaurant_id, name): para autocompletado o b√∫squeda de productos.
   - √çndices en claves for√°neas (client_id, branch_id, etc.) para agilizar JOIN.  

   Esto mejora el rendimiento en lectura sin penalizar demasiado las escrituras.

7. Escalabilidad
   - El modelo est√° preparado para crecer horizontalmente, ya que todo est√° ligado a restaurant_id.
   - Puede adaptarse f√°cilmente a particionamiento por fecha o restaurante si el volumen lo exige.

8. Seguridad
   - Se model√≥ la tabla users con control de roles y estado (A, I, B) para habilitar/deshabilitar accesos.
   - Las contrase√±as se almacenan como password_hash (no texto plano), siguiendo buenas pr√°cticas.

9. Auditor√≠a y Regulaci√≥n
    - La combinaci√≥n de campos como *created_by_user_id, status, changed_at, email* y trazabilidad por entidad permiten un dise√±o audit-ready.
    - Compatible con implementaciones de pgAudit para cumplimiento regulatorio si se requiere.

---

## ‚öôÔ∏è Parte 2: Optimizaci√≥n de Consultas

Dada la siguiente consulta:

```sql
SELECT p.id, p.total, c.name, r.name
FROM orders p
JOIN clients c ON p.client_id = c.id
JOIN restaurants r ON p.restaurant_id = r.id
WHERE p.status = 'sent'
AND p.created_at >= NOW() - interval '7 days';
```
## Tarea 1

### Explica c√≥mo identificar√≠as cuellos de botella

   Realizar√≠a un an√°lisis de plan de ejecuci√≥n con (EXPLAIN ANALYZE)  
     
   Un ejemplo real simplificado de un resultado seria:
   
   ```sql
Seq Scan on orders ‚Üí 10,000 filas le√≠das  
Rows removed by filter ‚Üí 8,815  
Hash Join con clients  
Hash Join con restaurants  
Tiempo total ‚Üí 5.3 ms
   ```
   En base al ejemplo podemos identificar los siguientes problemas:
   - Se hace Seq Scan en orders, lo que significa que PostgreSQL lee toda la tabla completa para filtrar los pedidos enviados.
   - Se procesan 10,000 filas, pero se devuelven solo 1,185.
   - Las uniones (JOIN) usan Hash Join, lo que no es eficiente si hay √≠ndices disponibles.

## Tarea 2

### Prop√≥n al menos 2 formas de optimizar la consulta

### Soluci√≥n 1:
   Crear un √≠ndice compuesto para los filtros

   ```sql
CREATE INDEX idx_orders_status_created ON orders (status, created_at);
   ```
   
   ***Ventajas***
   - Permite que PostgreSQL filtre r√°pidamente los pedidos sent creados en los √∫ltimos 7 d√≠as sin escanear toda la tabla.
   - Se adapta perfectamente al WHERE status = 'sent' AND created_at >= NOW() - interval '7 days'.

### Soluci√≥n 2:
   √çndices adicionales para mejorar los JOIN

   ```sql
CREATE INDEX idx_orders_client_id ON orders(client_id);
CREATE INDEX idx_orders_restaurant_id ON orders(restaurant_id);
CREATE INDEX idx_clients_id ON clients(id);
CREATE INDEX idx_restaurants_id ON restaurants(id);
   ```
   
   ***Ventajas***
   - Aceleran las uniones entre tablas.
   - Reducen la necesidad de escaneos completos en tablas grandes.
   - Fundamental en entornos multitenant y de alto volumen.

### Soluci√≥n 3:
   Evaluar particionamiento de la tabla orders (si es muy grande)

   ```sql
CREATE TABLE orders_2025_07 PARTITION OF orders
FOR VALUES FROM ('2025-07-01') TO ('2025-08-01');
   ```
   
   ***Ventajas***
   - PostgreSQL accede directamente a la partici√≥n de los √∫ltimos 7 d√≠as.
   - Reduce dram√°ticamente el costo de escaneo y mejora la escalabilidad.

## Tarea 3

### Justifica c√≥mo afectar√≠a la soluci√≥n al sistema en producci√≥n

   Con las soluciones anteriormente indicadas el impacto en producci√≥n seria:
   - √çndices bien dise√±ados, mejora la reducci√≥n de tiempo de consulta de milisegundos a microsegundos.
   - Evitar Seq Scan, mejora la eficiencia, especialmente en tablas con alta concurrencia.
   - Mejora de JOIN con √≠ndices, reducci√≥n de CPU y RAM usada en operaciones complejas.
   - Particionamiento (si aplica), Escalabilidad horizontal, menor carga I/O.

**En conclusi√≥n**  
- Optimizar consultas en PostgreSQL no solo mejora la velocidad, sino tambi√©n la estabilidad del sistema, reduce el consumo de recursos y mejora la experiencia del usuario.
- Un simple √≠ndice o una correcta estrategia de particionado puede ahorrar segundos por consulta, lo cual se traduce en horas ahorradas al d√≠a en sistemas con alta concurrencia.

---

## üß™ Parte 3: Redis

### 1. ¬øC√≥mo usar√≠as Redis para mejorar el rendimiento del sistema en lectura de √≥rdenes por estado?
Redis es una base de datos en memoria extremadamente r√°pida, ideal para mejorar el rendimiento en consultas de lectura intensiva.

**Estrategia:**
Utilizar Redis como capa de **cach√©** para almacenar resultados frecuentes de consultas, por ejemplo:

- Pedidos por estado (`sent`, `delivered`, etc.)
- Conteo de pedidos por d√≠a o por estado
- √öltimos pedidos realizados

**Ejemplo:**
```plaintext
Clave:  orders:status:sent
Valor:  JSON con los IDs o detalles resumidos de los pedidos
TTL:    60 segundos (Time To Live, para evitar desactualizaci√≥n)
   ```
Se puede establecer un `TTL` (Time To Live) de 30 a 60 segundos para asegurar la actualizaci√≥n autom√°tica de la cach√©, esto permite que, si un cliente o dashboard consulta constantemente los pedidos enviados, la informaci√≥n se entregue desde Redis en milisegundos, sin tocar PostgreSQL.

### 2. ¬øQu√© estrategias usar√≠as para evitar inconsistencias entre Redis y PostgreSQL?

Redis no reemplaza a PostgreSQL como fuente de verdad, por eso se deben tomar medidas para evitar inconsistencias:

**Estrategias recomendadas:**

1. Cache-aside (lazy loading):
   - Consultar Redis primero.
   - Si no hay datos, leer desde PostgreSQL y almacenar en Redis.
   - Invalida o actualiza Redis manualmente despu√©s de cada escritura.

2. TTL corto:
   - Establecer expiraci√≥n autom√°tica de los datos para garantizar frescura sin intervenci√≥n manual.

3. Eventos de invalidaci√≥n:
   - Emitir eventos (pub/sub, webhooks o triggers) que actualicen o eliminen cach√© cuando cambia el estado del pedido.

4. Marcas de tiempo en la cach√©:
   - Incluir `last_updated_at` para validar que la informaci√≥n a√∫n sea v√°lida antes de usarla.

### 3. ¬øCu√°ndo preferir√≠as evitar usar Redis en un sistema de alta concurrencia?
Aunque Redis es muy r√°pido, no siempre es la mejor soluci√≥n en sistemas de alta concurrencia. Algunos escenarios en los que preferir√≠a evitarlo o tener cuidado seria en:

‚ùå Sistemas con alta tasa de cambio: (Cuando los datos cambian constantemente)
- Si los pedidos cambian de estado constantemente (por ejemplo: cada segundo), Redis puede quedar obsoleto m√°s r√°pido de lo que puede actualizarse y puede estar propenso a errores.
- Mantener la cach√© sincronizada entre PostgreSQL y Redis se vuelve costoso.

‚ùå L√≥gica cr√≠tica o financiera: (Cuando la l√≥gica de negocio es cr√≠tica)
- No es recomendable confiar en Redis para operaciones que requieren consistencia fuerte.
- Como ejemplo: No usar Redis como fuente para pagos, saldos o stock, inventarios o auditor√≠a. Puede mostrar informaci√≥n desactualizada y/o valores incorrectos.

‚ùå Casos donde la consistencia es m√°s importante que el rendimiento: (Cuando la latencia de sincronizaci√≥n importa mucho)
- Redis es ideal para **rendimiento**, pero no para **consistencia estricta**.
- Si Redis no se actualiza al mismo tiempo que PostgreSQL, los usuarios podr√≠an ver datos desfasados.
- En sistemas de auditor√≠a, legal o financiero, esto no es aceptable.

**A continuaci√≥n, comparto un peque√±o cuadro resumen de cuando usar y no usar Redis:**

| Situaci√≥n                          | ¬øRedis es recomendable? | Comentario                                                 |
|-----------------------------------|--------------------------|-------------------------------------------------------------|
| Lecturas repetidas y costosas     | ‚úÖ S√≠                    | Ideal para acelerar consultas frecuentes                   |
| Datos que cambian constantemente  | ‚ö†Ô∏è Con precauci√≥n        | Podr√≠a quedar desactualizado                               |
| Datos cr√≠ticos o financieros      | ‚ùå No                    | Usar solo PostgreSQL como fuente                           |

---

## üßØ Parte 4: Respaldo y Recuperaci√≥n
### 1. Describe tu estrategia de backup para una base de datos de 100 GB que no puede tener m√°s de 5 minutos de p√©rdida de datos (RPO).
Si el objetivo es no perder m√°s de 5 minutos de datos en caso de fallo (RPO: Recovery Point Objective), en base a mi experiencia usar√≠a la siguiente estrategia:

WAL Archiving + Backups peri√≥dicos + Monitoreo
- Backups completos diarios
  - Realizar backups f√≠sicos diarios usando pg_basebackup o snapshots de disco en RDS/AWS EBS.
  - Programarlos en horarios de baja carga.
    
- Archivado de WALs (Write-Ahead Logs):
  - Configurar√≠a PostgreSQL para guardar y archivar los WALs (con `archive_mode = on` y `archive_command`).
  - Esto me permite generar la recuperaci√≥n punto a punto (PITR) hasta el √∫ltimo minuto, reproduciendo cambios desde el √∫ltimo backup completo.
    
- Incrementar frecuencia de backup para Reducir el tama√±o del RPO:
  - En lugar de esperar 24h entre backups, se pueden hacer backups incrementales o diferenciales cada hora o 6 horas.
  - Validar que los WALs se archiven con frecuencia (cada 1‚Äì5 min).
    
- Si PostgreSQL lo tenemos en RDS/AWS:
  - Configurar√≠a automated backups + retenci√≥n de snapshots.
  - Habilitar√≠a el point-in-time recovery (PITR) nativo.

### 2. ¬øC√≥mo configurar√≠as una r√©plica de solo lectura en PostgreSQL?
De manera on-premise realizar√≠a lo siguiente:

1. En el **servidor primario**:
   - Configurar:
     ```conf
     wal_level = replica
     max_wal_senders = 5
     archive_mode = on
     ```
   - Crear usuario con permisos de `REPLICATION`.

2. En el **servidor secundario**:
   - Ejecutar `pg_basebackup`.
   - Crear archivo `standby.signal` en el directorio `data/`.
   - Configurar `primary_conninfo` con los datos del servidor primario.

Como Resultado obtendre que la r√©plica funcione en **modo hot standby** (solo lectura + sincronizaci√≥n en tiempo real).

En un SaaS por ejemplo RDS/AWS:
- Simplemente seleccionar√≠a "Create read replica" desde la consola de RDS y elegir√≠a la instancia primaria.
- AWS se encarga de la replicaci√≥n, failover y sincronizaci√≥n autom√°ticamente.

### 3. ¬øQu√© herramienta o enfoque usar√≠as para automatizar y validar los backups?
En base a mi experiencia para automatizar recomiendo usar las siguientes herramientas:  

pgBackRest
  - Soporta backups incrementales, compresi√≥n, encriptaci√≥n y PITR.
  - Verificaci√≥n autom√°tica y restore por timestamp.

Barman
  - Especializado en recuperaci√≥n ante desastres y m√∫ltiples servidores.

`pg_basebackup` + `cron` o `pg_dump` para entornos m√°s simples.

En un SaaS por ejemplo RDS/AWS:
- Utiliza snapshots autom√°ticos configurables por d√≠as/retenci√≥n.
- Soporte de recuperaci√≥n point-in-time (PITR).

Para validaci√≥n de Backups, se debe automatizar scripts para:
  - Verificar el tama√±o y √©xito de cada backup.
  - Simulaciones de restauraci√≥n con `pg_restore --list`.
  - Notificaciones v√≠a correo o Slack si un backup falla.

En entornos productivos, tambi√©n es buena pr√°ctica restaurar peri√≥dicamente en un entorno de pruebas.

**A continuaci√≥n, comparto un cuadro resumen con la soluci√≥n en base a las 3 preguntas:**

| Objetivo                        | Soluci√≥n recomendada                                       |
|----------------------------------|-------------------------------------------------------------|
| RPO ‚â§ 5 minutos                  | Backups + WAL Archiving + PITR                             |
| Replica de solo lectura          | pg_basebackup + hot standby o AWS RDS Read Replica         |
| Automatizaci√≥n y validaci√≥n      | pgBackRest / Barman / Cron + monitoreo y alertas           |

## üîê Parte 5: Seguridad y Acceso
### 1. ¬øQu√© pr√°cticas aplicar√≠as para proteger las credenciales de conexi√≥n a la base de datos?
Proteger las credenciales de acceso es fundamental para evitar accesos no autorizados o fuga de informaci√≥n, algunas buenas pr√°cticas son:

1. Uso de gestores de secretos o variables de entorno
   - Nunca guardar credenciales en el c√≥digo fuente.
   - En entornos on-premise, utilizar variables de entorno seguras (.env con protecci√≥n de lectura).
   - Usar gestores como:
     - AWS Secrets Manager
     - HashiCorp Vault

2. Cambio de contrase√±as periodicamente
   - Establecer pol√≠ticas para que las contrase√±as se renueven cada cierto tiempo (por ejemplo, cada 90 d√≠as).
   - Automatizar este proceso si es posible y m√°s aun en sistemas cloud.

3. Conexiones cifradas (SSL/TLS)
   - Asegurar que todas las conexiones usen cifrado (`ssl = on` en PostgreSQL).
   - Especialmente cr√≠tico en entornos cloud o redes p√∫blicas.

4. Principio de menor privilegio
   - Cada aplicaci√≥n o usuario solo debe tener los permisos estrictamente necesarios.
   - Separar usuarios para lectura, escritura o administraci√≥n.
   
### 2. ¬øC√≥mo controlar√≠as el acceso a los datos entre entornos (producci√≥n, staging, desarrollo)?
Es clave y fundamental poder separar correctamente los entornos para evitar errores y fugas de informaci√≥n, en mi experiencia tomar√≠a las siguientes acciones:

1. Bases de datos y roles separados por entorno
   - Instancias o bases independientes por entorno.
   - Roles distintos: `app_prod`, `app_staging`, `app_dev`.

2. Pol√≠ticas de red restrictivas
   - Configurar firewalls o grupos de seguridad que controlen qu√© IPs pueden acceder a cada entorno.
   - Como ejemplo podria ser que para staging solo sea accesible desde ciertas IPs internas.

3. Datos ficticios en staging/desarrollo
   - Nunca usar datos reales de clientes en entornos de desarrollo.
   - Aplicar herramientas de nonimizaci√≥n o generaci√≥n de datos ficticios.
   - Usar politicas de privacidad de datos.

4. Restricciones v√≠a IAM (en la nube)
   - Por ejemplo, en AWS usar pol√≠ticas de IAM para restricci√≥n por entorno, para evitar el acceso de usuarios comunes a producci√≥n.

### 3. ¬øC√≥mo implementar√≠as auditor√≠a de acceso a datos sensibles?
Auditar quienes acceden a informaci√≥n cr√≠tica y/o sencible, es esencial para cumplir con normativas como (GDPR o HIPAA), yo aplicar√≠a los siguientes metodos recomendados:

1. Configuraci√≥n de registro de logs de auditor√≠a
   - Configurar `log_statement = 'all'` o tambien podemos usar `log_statement = 'mod'` para registrar solo `INSERT`, `UPDATE`, `DELETE`.
   - Complementar con log_duration y log_connections.

2. Extensi√≥n `pgaudit`
   - Al instalar y configurar la extensi√≥n pgaudit para un control granular de auditor√≠a, nos permite registrar SELECT, DDL y accesos a tablas espec√≠ficas.

3. Triggers de auditor√≠a personalizados
   - Para auditor√≠a a nivel de tabla, se pueden crear AFTER INSERT/UPDATE/DELETE triggers que escriban en una tabla de auditor√≠a (por ejemplo: audit_log).

5. Centralizaci√≥n y monitoreo
   - Al tener los logs, podemos enviarlos a un sistema de an√°lisis centralizado como:
     - CloudWatch (AWS)
     - ELK Stack (Elasticsearch + Logstash + Kibana)
   - Tambien podemos generar alertas paraaccesos sospechosos.
